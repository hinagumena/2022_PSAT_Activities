{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7ff95d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Win/Lose', 'Season', 'TR', 'TS', 'effi', '최다연속득점', '3P%',\n",
       "       '2P%', 'AST_Rating', 'TR_away', 'TS_away', 'effi_away', '최다연속득점_away',\n",
       "       '3P%_away', '2P%_away', 'AST_Rating_away'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score, accuracy_score, f1_score\n",
    "\n",
    "data=pd.read_csv(\"C:/Users/shn20/Documents/카카오톡 받은 파일/home_away_nba_9col.csv\",encoding='CP949')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ae9d3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "fcc076f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Season']!=2122]\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b119b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 시즌별로 train, test를 나누기위한 리스트 작성\n",
    "season = [910, 1011, 1112, 1213, 1314, 1415, 1516, 1617, 1718, 1819, 1920]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "3491f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Logistic regression time series cross validation\n",
    "def logistic(C):\n",
    "    \n",
    "\n",
    "    accuracy = []\n",
    "    f1_score_list = []\n",
    "    bal_accuracy = []\n",
    "\n",
    "    for i in season :\n",
    "        ## 등차수열 이용해서 train, test 셋 나누고\n",
    "        train = data[data['Season'] <= i]\n",
    "        test = data[data['Season'] == i + 101]\n",
    "    \n",
    "        train = train.reset_index(drop=True)\n",
    "        test = test.reset_index(drop=True)\n",
    "    \n",
    "        ## X_train, Y_train 나누기\n",
    "        X_train = train.drop(['Win/Lose'], axis=1)\n",
    "        Y_train = train['Win/Lose']\n",
    "        X_test = test.drop(['Win/Lose'], axis=1)\n",
    "        Y_test = test['Win/Lose']\n",
    "    \n",
    "        ## 이제 시즌변수 필요없음\n",
    "        X_train = X_train.drop(['Season'], axis=1)\n",
    "        X_test = X_test.drop(['Season'], axis=1)\n",
    "    \n",
    "        ## 정규화(X_train)\n",
    "        scaler = StandardScaler() \n",
    "        scaler.fit(X_train) \n",
    "        X_train_scaled = scaler.transform(X_train) \n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    \n",
    "        ## 정규화(X_test)\n",
    "        ## 이때 X_train에 의해 fit된 scaler로 진행\n",
    "        X_test_scaled = scaler.transform(X_test) \n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "    \n",
    "        ## 일단 임의의 파라미터와 분류기로 모델 적합해봄\n",
    "    \n",
    "        ## 진짜 아무값이나 집어넣은거(파라미터 튜닝 예정)\n",
    "        model=LogisticRegression(C=C)\n",
    "        model.fit(X_train_scaled, Y_train) # SVM 분류 모델 훈련\n",
    "    \n",
    "        ## 예측하고 accuracy score 출력하게끔\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        #print('########################################')\n",
    "        #print('train set : ~',i)\n",
    "        #print('test set : ',i+101)\n",
    "        #print('accuracy score:', accuracy_score(Y_test, y_pred))\n",
    "        #print('f1 score:', f1_score(Y_test, y_pred))\n",
    "        #print('balanced_accuracy :',balanced_accuracy_score(Y_test, y_pred))\n",
    "        #print('########################################')\n",
    "        accuracy.append(accuracy_score(Y_test, y_pred))\n",
    "        f1_score_list.append(f1_score(Y_test, y_pred))\n",
    "        bal_accuracy.append(balanced_accuracy_score(Y_test, y_pred))\n",
    "\n",
    "    ## 모든 TimeSeriesCV과정에서의 평균 accuracy 출력\n",
    "    #print('C :',C)\n",
    "    #print('최종 accuracy 평균:', np.mean(accuracy))\n",
    "    #print('최종 f1_score 평균:', np.mean(f1_score_list))\n",
    "    #print('최종 balanced_accuracy 평균:', np.mean(bal_accuracy))\n",
    "    return([np.mean(accuracy),np.mean(f1_score_list),np.mean(bal_accuracy)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "5fe2f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8430778847578664, 0.847547594424529, 0.8398296126487939]\n",
      "[0.8410987887307709, 0.846066203861862, 0.8380287925029414]\n",
      "[0.8415911426385763, 0.8458376381389725, 0.8387184689016691]\n",
      "[0.8422283695760701, 0.8444123897642938, 0.8385655159726055]\n",
      "[0.8431313916892403, 0.8452975579412283, 0.839564433716587]\n",
      "[0.8447684520096712, 0.8468790755372493, 0.8413055388127652]\n",
      "[0.8448517723549991, 0.8470485620634521, 0.8417598284470212]\n",
      "[0.8465537814766201, 0.8490189642459628, 0.8436376375092891]\n",
      "[0.8473036624054577, 0.8497792836913537, 0.8446122027588401]\n",
      "[0.8480528347283346, 0.850630082590709, 0.8454100552674061]\n",
      "[0.8493671419604446, 0.8516938511099178, 0.8467439630014517]\n"
     ]
    }
   ],
   "source": [
    "for i in season :\n",
    "        ## 등차수열 이용해서 train, test 셋 나누고\n",
    "    train = data[data['Season'] <= i]\n",
    "    test = data[data['Season'] == i + 101]\n",
    "    \n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    \n",
    "        ## X_train, Y_train 나누기\n",
    "    X_train = train.drop(['Win/Lose'], axis=1)\n",
    "    Y_train = train['Win/Lose']\n",
    "    X_test = test.drop(['Win/Lose'], axis=1)\n",
    "    Y_test = test['Win/Lose']\n",
    "    \n",
    "        ## 이제 시즌변수 필요없음\n",
    "    X_train = X_train.drop(['Season'], axis=1)\n",
    "    X_test = X_test.drop(['Season'], axis=1)\n",
    "    \n",
    "        ## 정규화(X_train)\n",
    "    scaler = StandardScaler() \n",
    "    scaler.fit(X_train) \n",
    "    X_train_scaled = scaler.transform(X_train) \n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    \n",
    "        ## 정규화(X_test)\n",
    "        ## 이때 X_train에 의해 fit된 scaler로 진행\n",
    "    X_test_scaled = scaler.transform(X_test) \n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "    \n",
    "        ## 일단 임의의 파라미터와 분류기로 모델 적합해봄\n",
    "    \n",
    "        ## 진짜 아무값이나 집어넣은거(파라미터 튜닝 예정)\n",
    "    model=LogisticRegression()\n",
    "    model.fit(X_train_scaled, Y_train) # SVM 분류 모델 훈련\n",
    "    \n",
    "        ## 예측하고 accuracy score 출력하게끔\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "        #print('########################################')\n",
    "        #print('train set : ~',i)\n",
    "        #print('test set : ',i+101)\n",
    "        #print('accuracy score:', accuracy_score(Y_test, y_pred))\n",
    "        #print('f1 score:', f1_score(Y_test, y_pred))\n",
    "        #print('balanced_accuracy :',balanced_accuracy_score(Y_test, y_pred))\n",
    "        #print('########################################')\n",
    "    accuracy.append(accuracy_score(Y_test, y_pred))\n",
    "    f1_score_list.append(f1_score(Y_test, y_pred))\n",
    "    bal_accuracy.append(balanced_accuracy_score(Y_test, y_pred))\n",
    "\n",
    "    ## 모든 TimeSeriesCV과정에서의 평균 accuracy 출력\n",
    "    #print('C :',C)\n",
    "    #print('최종 accuracy 평균:', np.mean(accuracy))\n",
    "    #print('최종 f1_score 평균:', np.mean(f1_score_list))\n",
    "    #print('최종 balanced_accuracy 평균:', np.mean(bal_accuracy))\n",
    "    print([np.mean(accuracy),np.mean(f1_score_list),np.mean(bal_accuracy)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "bbb2d709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>bal_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.859026</td>\n",
       "      <td>0.859789</td>\n",
       "      <td>0.855246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.863421</td>\n",
       "      <td>0.863548</td>\n",
       "      <td>0.859923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863421</td>\n",
       "      <td>0.863548</td>\n",
       "      <td>0.859923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.862257</td>\n",
       "      <td>0.862642</td>\n",
       "      <td>0.858363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.861188</td>\n",
       "      <td>0.861586</td>\n",
       "      <td>0.857330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.857886</td>\n",
       "      <td>0.858631</td>\n",
       "      <td>0.854354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  Accuracy  F1_score  bal_Accuracy\n",
       "0   0.1  0.859026  0.859789      0.855246\n",
       "1   0.5  0.863421  0.863548      0.859923\n",
       "2   1.0  0.863421  0.863548      0.859923\n",
       "3   5.0  0.862257  0.862642      0.858363\n",
       "4  10.0  0.861188  0.861586      0.857330\n",
       "5  50.0  0.857886  0.858631      0.854354"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## parameter_tuning \n",
    "\n",
    "## 'C'에 있는 값 바꿔주면 됨..! -> 튜닝 하기 전 성능 확인 (나중에 튜닝 후 버전 있음)\n",
    "parameter_linear = pd.DataFrame({'C':[0.1, 0.5, 1, 5, 10, 50],\n",
    "                             'Accuracy':[0,0,0,0,0,0],\n",
    "                             'F1_score':[0,0,0,0,0,0],\n",
    "                             'bal_Accuracy':[0,0,0,0,0,0]})\n",
    "\n",
    "acc = []\n",
    "f1 = []\n",
    "bal = []\n",
    "for i in parameter_linear['C']:\n",
    "    acc.append(logistic(i)[0])\n",
    "    f1.append(logistic(i)[1])\n",
    "    bal.append(logistic(i)[2])\n",
    "parameter_linear['Accuracy'] = acc\n",
    "parameter_linear['F1_score'] = f1\n",
    "parameter_linear['bal_Accuracy'] = bal\n",
    "parameter_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2fd314c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-12 17:31:48,123]\u001b[0m A new study created in memory with name: no-name-0359b831-6fa7-4873-aa0e-3a91b9219a69\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,151]\u001b[0m Trial 0 finished with value: 0.9058823529411765 and parameters: {'C': 2.5899227065101296}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,190]\u001b[0m Trial 1 finished with value: 0.9058823529411765 and parameters: {'C': 5.3625783805718985}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,207]\u001b[0m Trial 2 finished with value: 0.9058823529411765 and parameters: {'C': 0.602913498636281}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,223]\u001b[0m Trial 3 finished with value: 0.8941176470588236 and parameters: {'C': 8.89307482142533}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,233]\u001b[0m Trial 4 finished with value: 0.9058823529411765 and parameters: {'C': 3.597077378114473}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,245]\u001b[0m Trial 5 finished with value: 0.8941176470588236 and parameters: {'C': 0.18272280959441797}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,253]\u001b[0m Trial 6 finished with value: 0.8941176470588236 and parameters: {'C': 7.538509586108794}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,263]\u001b[0m Trial 7 finished with value: 0.8941176470588236 and parameters: {'C': 7.622988236161693}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,282]\u001b[0m Trial 8 finished with value: 0.8941176470588236 and parameters: {'C': 6.99390536905385}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,292]\u001b[0m Trial 9 finished with value: 0.9058823529411765 and parameters: {'C': 3.6077326171590536}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,306]\u001b[0m Trial 10 finished with value: 0.9058823529411765 and parameters: {'C': 2.415448393674308}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,318]\u001b[0m Trial 11 finished with value: 0.9058823529411765 and parameters: {'C': 5.351088454695067}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,332]\u001b[0m Trial 12 finished with value: 0.9058823529411765 and parameters: {'C': 4.694039709627718}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,344]\u001b[0m Trial 13 finished with value: 0.9058823529411765 and parameters: {'C': 2.1675128456795205}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,354]\u001b[0m Trial 14 finished with value: 0.9058823529411765 and parameters: {'C': 5.4785283887314}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,367]\u001b[0m Trial 15 finished with value: 0.9058823529411765 and parameters: {'C': 1.8886964771358574}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,380]\u001b[0m Trial 16 finished with value: 0.9058823529411765 and parameters: {'C': 4.158519163982488}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,394]\u001b[0m Trial 17 finished with value: 0.8941176470588236 and parameters: {'C': 5.849595569138099}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,408]\u001b[0m Trial 18 finished with value: 0.8941176470588236 and parameters: {'C': 9.833930361686047}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,422]\u001b[0m Trial 19 finished with value: 0.9058823529411765 and parameters: {'C': 3.6892355498284366}. Best is trial 0 with value: 0.9058823529411765.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,435]\u001b[0m Trial 20 finished with value: 0.9176470588235294 and parameters: {'C': 1.1483730328392965}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,449]\u001b[0m Trial 21 finished with value: 0.9058823529411765 and parameters: {'C': 1.043307992074088}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,464]\u001b[0m Trial 22 finished with value: 0.9058823529411765 and parameters: {'C': 2.94510321909425}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,475]\u001b[0m Trial 23 finished with value: 0.9176470588235294 and parameters: {'C': 1.273900143851058}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,489]\u001b[0m Trial 24 finished with value: 0.9176470588235294 and parameters: {'C': 1.1155181397752114}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,502]\u001b[0m Trial 25 finished with value: 0.9176470588235294 and parameters: {'C': 1.2132598314625316}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,515]\u001b[0m Trial 26 finished with value: 0.9058823529411765 and parameters: {'C': 1.516427791967326}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,529]\u001b[0m Trial 27 finished with value: 0.9058823529411765 and parameters: {'C': 0.6112185860045236}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,543]\u001b[0m Trial 28 finished with value: 0.8941176470588236 and parameters: {'C': 0.09662564495041481}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,556]\u001b[0m Trial 29 finished with value: 0.9058823529411765 and parameters: {'C': 2.980019508647872}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,569]\u001b[0m Trial 30 finished with value: 0.9058823529411765 and parameters: {'C': 1.7346030196399085}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,581]\u001b[0m Trial 31 finished with value: 0.9176470588235294 and parameters: {'C': 1.1183522496512956}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,593]\u001b[0m Trial 32 finished with value: 0.9176470588235294 and parameters: {'C': 1.1448635514811731}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,606]\u001b[0m Trial 33 finished with value: 0.9058823529411765 and parameters: {'C': 2.5552531265500282}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,620]\u001b[0m Trial 34 finished with value: 0.9058823529411765 and parameters: {'C': 0.9424464908818999}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,632]\u001b[0m Trial 35 finished with value: 0.9058823529411765 and parameters: {'C': 0.5404606760531221}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,645]\u001b[0m Trial 36 finished with value: 0.9058823529411765 and parameters: {'C': 1.889109590605079}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,658]\u001b[0m Trial 37 finished with value: 0.9058823529411765 and parameters: {'C': 3.0524454611623977}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,672]\u001b[0m Trial 38 finished with value: 0.9058823529411765 and parameters: {'C': 0.48743175687110063}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,684]\u001b[0m Trial 39 finished with value: 0.8823529411764706 and parameters: {'C': 0.023309406959085788}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,696]\u001b[0m Trial 40 finished with value: 0.9176470588235294 and parameters: {'C': 1.3361498415338096}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,708]\u001b[0m Trial 41 finished with value: 0.9058823529411765 and parameters: {'C': 0.9184642859519848}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,719]\u001b[0m Trial 42 finished with value: 0.9058823529411765 and parameters: {'C': 2.108747046600994}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,733]\u001b[0m Trial 43 finished with value: 0.9058823529411765 and parameters: {'C': 1.5541166716882258}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,745]\u001b[0m Trial 44 finished with value: 0.9058823529411765 and parameters: {'C': 0.6262951796544841}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-12 17:31:48,758]\u001b[0m Trial 45 finished with value: 0.9058823529411765 and parameters: {'C': 2.288307296950874}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,771]\u001b[0m Trial 46 finished with value: 0.9058823529411765 and parameters: {'C': 1.5281391453316515}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,784]\u001b[0m Trial 47 finished with value: 0.9058823529411765 and parameters: {'C': 2.693528243695415}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,798]\u001b[0m Trial 48 finished with value: 0.9176470588235294 and parameters: {'C': 1.3802281731609811}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,812]\u001b[0m Trial 49 finished with value: 0.9058823529411765 and parameters: {'C': 0.294680228927395}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,824]\u001b[0m Trial 50 finished with value: 0.8941176470588236 and parameters: {'C': 6.46548250594023}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,836]\u001b[0m Trial 51 finished with value: 0.9176470588235294 and parameters: {'C': 1.255124439257863}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,848]\u001b[0m Trial 52 finished with value: 0.9058823529411765 and parameters: {'C': 0.912980836818919}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,860]\u001b[0m Trial 53 finished with value: 0.9058823529411765 and parameters: {'C': 1.9844948313047843}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,872]\u001b[0m Trial 54 finished with value: 0.9058823529411765 and parameters: {'C': 3.5662933604408122}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,884]\u001b[0m Trial 55 finished with value: 0.9176470588235294 and parameters: {'C': 1.364376965726802}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,898]\u001b[0m Trial 56 finished with value: 0.9058823529411765 and parameters: {'C': 1.7297964544797264}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,912]\u001b[0m Trial 57 finished with value: 0.8941176470588236 and parameters: {'C': 8.470676303825584}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,927]\u001b[0m Trial 58 finished with value: 0.9058823529411765 and parameters: {'C': 0.7749038691649719}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,939]\u001b[0m Trial 59 finished with value: 0.9058823529411765 and parameters: {'C': 4.356416975779425}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,950]\u001b[0m Trial 60 finished with value: 0.9058823529411765 and parameters: {'C': 2.313365871620397}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,962]\u001b[0m Trial 61 finished with value: 0.9176470588235294 and parameters: {'C': 1.313185123382286}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,972]\u001b[0m Trial 62 finished with value: 0.9176470588235294 and parameters: {'C': 1.190435432106227}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,983]\u001b[0m Trial 63 finished with value: 0.9176470588235294 and parameters: {'C': 1.3978038144786649}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:48,996]\u001b[0m Trial 64 finished with value: 0.9058823529411765 and parameters: {'C': 0.35999068082510066}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:49,009]\u001b[0m Trial 65 finished with value: 0.9058823529411765 and parameters: {'C': 0.7413646906529021}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:49,024]\u001b[0m Trial 66 finished with value: 0.9058823529411765 and parameters: {'C': 2.667746366349604}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:49,036]\u001b[0m Trial 67 finished with value: 0.9058823529411765 and parameters: {'C': 1.6775970997675755}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:49,050]\u001b[0m Trial 68 finished with value: 0.9058823529411765 and parameters: {'C': 3.351718764578923}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n",
      "\u001b[32m[I 2022-05-12 17:31:49,065]\u001b[0m Trial 69 finished with value: 0.9058823529411765 and parameters: {'C': 2.100271673542686}. Best is trial 20 with value: 0.9176470588235294.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 튜닝 -> 옵튜나 함수 써서 (성능이 조금 감소함....)\n",
    "import optuna\n",
    "def logreg_objective(trial):\n",
    "    \n",
    "    c = trial.suggest_float('C', 1e-10, 10)\n",
    "    #r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    \n",
    "    model =  LogisticRegression(max_iter=5000, C=c)\n",
    "    model.fit(X_train_scaled, Y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    scores=accuracy_score(Y_test, y_pred)\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(logreg_objective, n_trials=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e298108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 파라미터 튜닝 이후 성능 확인\n",
    "def logisticr(x):\n",
    "    accuracy = []\n",
    "    f1_score_list = []\n",
    "    bal_accuracy = []\n",
    "    \n",
    "    for i in season :\n",
    "        ## 등차수열 이용해서 train, test 셋 나누고\n",
    "        train = data[data['Season'] <= i]\n",
    "        test = data[data['Season'] == i + 101]\n",
    "    \n",
    "        train = train.reset_index(drop=True)\n",
    "        test = test.reset_index(drop=True)\n",
    "    \n",
    "        ## X_train, Y_train 나누기\n",
    "        X_train = train.drop(['Win/Lose'], axis=1)\n",
    "        Y_train = train['Win/Lose']\n",
    "        X_test = test.drop(['Win/Lose'], axis=1)\n",
    "        Y_test = test['Win/Lose']\n",
    "    \n",
    "        ## 이제 시즌변수 필요없음\n",
    "        X_train = X_train.drop(['Season'], axis=1)\n",
    "        X_test = X_test.drop(['Season'], axis=1)\n",
    "    \n",
    "        ## SVM모델에서의 정규화(X_train)\n",
    "        scaler = StandardScaler() \n",
    "        scaler.fit(X_train) \n",
    "        X_train_scaled = scaler.transform(X_train) \n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    \n",
    "        ## SVM모델에서의 정규화(X_test)\n",
    "        ## 이때 X_train에 의해 fit된 scaler로 진행\n",
    "        X_test_scaled = scaler.transform(X_test) \n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "    \n",
    "        ## 일단 임의의 파라미터와 분류기로 모델 적합해봄\n",
    "    \n",
    "        ## 진짜 아무값이나 집어넣은거(파라미터 튜닝 예정)\n",
    "        model=LogisticRegression(**x)\n",
    "        model.fit(X_train_scaled, Y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    ## 예측하고 accuracy score 출력하게끔\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        print('########################################')\n",
    "        print('train set : ~',i)\n",
    "        print('test set : ',i+101)\n",
    "        print('accuracy score:', accuracy_score(Y_test, y_pred))\n",
    "        print('f1 score:', f1_score(Y_test, y_pred))\n",
    "        print('balanced_accuracy :',balanced_accuracy_score(Y_test, y_pred))\n",
    "        print('########################################')\n",
    "        accuracy.append(accuracy_score(Y_test, y_pred))\n",
    "        f1_score_list.append(f1_score(Y_test, y_pred))\n",
    "        bal_accuracy.append(balanced_accuracy_score(Y_test, y_pred))\n",
    "\n",
    "    ## 모든 TimeSeriesCV과정에서의 평균 accuracy 출력\n",
    "    print(x)\n",
    "    print('최종 accuracy 평균:', np.mean(accuracy))\n",
    "    print('최종 f1_score 평균:', np.mean(f1_score_list))\n",
    "    print('최종 balanced_accuracy 평균:', np.mean(bal_accuracy))\n",
    "    return([np.mean(accuracy),np.mean(f1_score_list),np.mean(bal_accuracy)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "23086609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.1483730328392965}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par=study.best_trial.params\n",
    "par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "512b2fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "train set : ~ 910\n",
      "test set :  1011\n",
      "accuracy score: 0.7901234567901234\n",
      "f1 score: 0.8411214953271028\n",
      "balanced_accuracy : 0.7566287878787878\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1011\n",
      "test set :  1112\n",
      "accuracy score: 0.7738095238095238\n",
      "f1 score: 0.7956989247311829\n",
      "balanced_accuracy : 0.7768009075439593\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1112\n",
      "test set :  1213\n",
      "accuracy score: 0.8588235294117647\n",
      "f1 score: 0.8378378378378378\n",
      "balanced_accuracy : 0.8628571428571428\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1213\n",
      "test set :  1314\n",
      "accuracy score: 0.8651685393258427\n",
      "f1 score: 0.7931034482758621\n",
      "balanced_accuracy : 0.8330592105263157\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1314\n",
      "test set :  1415\n",
      "accuracy score: 0.8765432098765432\n",
      "f1 score: 0.8780487804878049\n",
      "balanced_accuracy : 0.8765243902439024\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1415\n",
      "test set :  1516\n",
      "accuracy score: 0.9069767441860465\n",
      "f1 score: 0.9069767441860465\n",
      "balanced_accuracy : 0.9074675324675325\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1516\n",
      "test set :  1617\n",
      "accuracy score: 0.8481012658227848\n",
      "f1 score: 0.8536585365853658\n",
      "balanced_accuracy : 0.8594771241830066\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1617\n",
      "test set :  1718\n",
      "accuracy score: 0.9146341463414634\n",
      "f1 score: 0.9278350515463918\n",
      "balanced_accuracy : 0.91875\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1718\n",
      "test set :  1819\n",
      "accuracy score: 0.8780487804878049\n",
      "f1 score: 0.8809523809523809\n",
      "balanced_accuracy : 0.8845693779904307\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1819\n",
      "test set :  1920\n",
      "accuracy score: 0.8795180722891566\n",
      "f1 score: 0.8863636363636365\n",
      "balanced_accuracy : 0.8789198606271778\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1920\n",
      "test set :  2021\n",
      "accuracy score: 0.9176470588235294\n",
      "f1 score: 0.9090909090909091\n",
      "balanced_accuracy : 0.9154656319290466\n",
      "########################################\n",
      "{'C': 1.1483730328392965}\n",
      "최종 accuracy 평균: 0.8644903933785986\n",
      "최종 f1_score 평균: 0.8646079768531383\n",
      "최종 balanced_accuracy 평균: 0.8609563605679367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8644903933785986, 0.8646079768531383, 0.8609563605679367]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터 튜닝 이후 성능 확인\n",
    "logisticr(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "68bc77d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     c     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 5.247   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 6.689   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8645  \u001b[0m | \u001b[95m 1.584   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 6.71    \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 0.8124  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 2.956   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 2.093   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.838   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 2.334   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 3.803   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.584   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 8.36    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8317  \u001b[0m | \u001b[0m 0.001628\u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 9.181   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 4.54    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 7.615   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 5.877   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.143   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 3.364   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 9.598   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 4.892   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 8.753   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 0.9816  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 7.223   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 4.17    \u001b[0m |\n",
      "| \u001b[95m 27      \u001b[0m | \u001b[95m 0.8656  \u001b[0m | \u001b[95m 1.356   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 2.67    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 7.987   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.291   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 6.239   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 5.55    \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 3.167   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.454   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 3.579   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.967   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.404   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 0.6013  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 6.997   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 8.969   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 2.507   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 4.355   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 9.802   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 5.068   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 3.982   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.497   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 6.441   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 9.389   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.709   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 8.553   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 7.422   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 4.716   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 7.807   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 2.816   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 8.174   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 5.706   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 6.059   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 2.205   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.8623  \u001b[0m | \u001b[0m 5.4     \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 0.7     \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.8646  \u001b[0m | \u001b[0m 0.4615  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 3.267   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 1.075   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.8646  \u001b[0m | \u001b[0m 0.3906  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.433   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 3.059   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.646   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 2.03    \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.375   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 3.467   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.446   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 2.42    \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.8645  \u001b[0m | \u001b[0m 1.776   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.416   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.365   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.39    \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.347   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.449   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.424   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.351   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.383   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.397   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.448   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.411   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.354   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.371   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.424   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.451   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.439   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.343   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 6.869   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.348   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.38    \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.394   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.405   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.363   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.417   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.43    \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.45    \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.387   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.348   \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.372   \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.341   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.398   \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 1.411   \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# 베이지안 최적화\n",
    "def black_box_func(c):\n",
    "    return (logistic(c)[0])\n",
    "    \n",
    "# Search할 하이퍼파라미터 범위 정의\n",
    "pbounds = {'c': (1e-10, 10)}\n",
    "\n",
    "# Bayesian Optimization을 이용해서 최적의 파라미터 찾아내기\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "optimizer = BayesianOptimization(f=black_box_func,\n",
    "                                pbounds=pbounds,\n",
    "                                random_state=4848)\n",
    "# 미지의 함수 반환값을 최대화하도록 반복하면서 최적의 파라미터 검색\n",
    "optimizer.maximize(init_points=5, n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "293f6214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.865559912095176, 'params': {'c': 1.3563266165995378}}\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.max)\n",
    "par2= {'C':1.3563266165995378 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "814a5587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "train set : ~ 910\n",
      "test set :  1011\n",
      "accuracy score: 0.7901234567901234\n",
      "f1 score: 0.8411214953271028\n",
      "balanced_accuracy : 0.7566287878787878\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1011\n",
      "test set :  1112\n",
      "accuracy score: 0.7738095238095238\n",
      "f1 score: 0.7956989247311829\n",
      "balanced_accuracy : 0.7768009075439593\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1112\n",
      "test set :  1213\n",
      "accuracy score: 0.8705882352941177\n",
      "f1 score: 0.8493150684931505\n",
      "balanced_accuracy : 0.8728571428571428\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1213\n",
      "test set :  1314\n",
      "accuracy score: 0.8651685393258427\n",
      "f1 score: 0.7931034482758621\n",
      "balanced_accuracy : 0.8330592105263157\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1314\n",
      "test set :  1415\n",
      "accuracy score: 0.8765432098765432\n",
      "f1 score: 0.8780487804878049\n",
      "balanced_accuracy : 0.8765243902439024\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1415\n",
      "test set :  1516\n",
      "accuracy score: 0.9069767441860465\n",
      "f1 score: 0.9069767441860465\n",
      "balanced_accuracy : 0.9074675324675325\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1516\n",
      "test set :  1617\n",
      "accuracy score: 0.8481012658227848\n",
      "f1 score: 0.8536585365853658\n",
      "balanced_accuracy : 0.8594771241830066\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1617\n",
      "test set :  1718\n",
      "accuracy score: 0.9146341463414634\n",
      "f1 score: 0.9278350515463918\n",
      "balanced_accuracy : 0.91875\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1718\n",
      "test set :  1819\n",
      "accuracy score: 0.8780487804878049\n",
      "f1 score: 0.8809523809523809\n",
      "balanced_accuracy : 0.8845693779904307\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1819\n",
      "test set :  1920\n",
      "accuracy score: 0.8795180722891566\n",
      "f1 score: 0.8863636363636365\n",
      "balanced_accuracy : 0.8789198606271778\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1920\n",
      "test set :  2021\n",
      "accuracy score: 0.9176470588235294\n",
      "f1 score: 0.9090909090909091\n",
      "balanced_accuracy : 0.9154656319290466\n",
      "########################################\n",
      "{'C': 1.3563266165995378}\n",
      "최종 accuracy 평균: 0.865559912095176\n",
      "최종 f1_score 평균: 0.8656513614581667\n",
      "최종 balanced_accuracy 평균: 0.8618654514770276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.865559912095176, 0.8656513614581667, 0.8618654514770276]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticr(par2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d9e94bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid={\"C\":np.logspace(-3,3,7)}\n",
    "model=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(model,grid,cv=11)\n",
    "logreg_cv.fit(X_train_scaled, Y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "30faa704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "train set : ~ 910\n",
      "test set :  1011\n",
      "accuracy score: 0.7901234567901234\n",
      "f1 score: 0.8411214953271028\n",
      "balanced_accuracy : 0.7566287878787878\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1011\n",
      "test set :  1112\n",
      "accuracy score: 0.7738095238095238\n",
      "f1 score: 0.7956989247311829\n",
      "balanced_accuracy : 0.7768009075439593\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1112\n",
      "test set :  1213\n",
      "accuracy score: 0.8588235294117647\n",
      "f1 score: 0.8378378378378378\n",
      "balanced_accuracy : 0.8628571428571428\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1213\n",
      "test set :  1314\n",
      "accuracy score: 0.8651685393258427\n",
      "f1 score: 0.7931034482758621\n",
      "balanced_accuracy : 0.8330592105263157\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1314\n",
      "test set :  1415\n",
      "accuracy score: 0.8765432098765432\n",
      "f1 score: 0.8780487804878049\n",
      "balanced_accuracy : 0.8765243902439024\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1415\n",
      "test set :  1516\n",
      "accuracy score: 0.9069767441860465\n",
      "f1 score: 0.9069767441860465\n",
      "balanced_accuracy : 0.9074675324675325\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1516\n",
      "test set :  1617\n",
      "accuracy score: 0.8481012658227848\n",
      "f1 score: 0.8536585365853658\n",
      "balanced_accuracy : 0.8594771241830066\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1617\n",
      "test set :  1718\n",
      "accuracy score: 0.9146341463414634\n",
      "f1 score: 0.9278350515463918\n",
      "balanced_accuracy : 0.91875\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1718\n",
      "test set :  1819\n",
      "accuracy score: 0.8780487804878049\n",
      "f1 score: 0.8809523809523809\n",
      "balanced_accuracy : 0.8845693779904307\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1819\n",
      "test set :  1920\n",
      "accuracy score: 0.8795180722891566\n",
      "f1 score: 0.8863636363636365\n",
      "balanced_accuracy : 0.8789198606271778\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1920\n",
      "test set :  2021\n",
      "accuracy score: 0.9058823529411765\n",
      "f1 score: 0.8974358974358975\n",
      "balanced_accuracy : 0.9041019955654102\n",
      "########################################\n",
      "{'C': 1.0}\n",
      "최종 accuracy 평균: 0.863420874662021\n",
      "최종 f1_score 평균: 0.8635484303390464\n",
      "최종 balanced_accuracy 평균: 0.859923302716697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.863420874662021, 0.8635484303390464, 0.859923302716697]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticr(logreg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5fcd6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#최종 튜닝된 파라미터\n",
    "#parameter1={'C':0.4033990683975486,'penalty':'l2','solver':'saga'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "afb11b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter1={'C':1.3563266165995378,'penalty':'l2','solver':'saga'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f2eef86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "train set : ~ 910\n",
      "test set :  1011\n",
      "accuracy score: 0.7901234567901234\n",
      "f1 score: 0.8411214953271028\n",
      "balanced_accuracy : 0.7566287878787878\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1011\n",
      "test set :  1112\n",
      "accuracy score: 0.7738095238095238\n",
      "f1 score: 0.7956989247311829\n",
      "balanced_accuracy : 0.7768009075439593\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1112\n",
      "test set :  1213\n",
      "accuracy score: 0.8705882352941177\n",
      "f1 score: 0.8493150684931505\n",
      "balanced_accuracy : 0.8728571428571428\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1213\n",
      "test set :  1314\n",
      "accuracy score: 0.8651685393258427\n",
      "f1 score: 0.7931034482758621\n",
      "balanced_accuracy : 0.8330592105263157\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1314\n",
      "test set :  1415\n",
      "accuracy score: 0.8765432098765432\n",
      "f1 score: 0.8780487804878049\n",
      "balanced_accuracy : 0.8765243902439024\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1415\n",
      "test set :  1516\n",
      "accuracy score: 0.9069767441860465\n",
      "f1 score: 0.9069767441860465\n",
      "balanced_accuracy : 0.9074675324675325\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1516\n",
      "test set :  1617\n",
      "accuracy score: 0.8481012658227848\n",
      "f1 score: 0.8536585365853658\n",
      "balanced_accuracy : 0.8594771241830066\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1617\n",
      "test set :  1718\n",
      "accuracy score: 0.9146341463414634\n",
      "f1 score: 0.9278350515463918\n",
      "balanced_accuracy : 0.91875\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1718\n",
      "test set :  1819\n",
      "accuracy score: 0.8780487804878049\n",
      "f1 score: 0.8809523809523809\n",
      "balanced_accuracy : 0.8845693779904307\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1819\n",
      "test set :  1920\n",
      "accuracy score: 0.8795180722891566\n",
      "f1 score: 0.8863636363636365\n",
      "balanced_accuracy : 0.8789198606271778\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1920\n",
      "test set :  2021\n",
      "accuracy score: 0.9176470588235294\n",
      "f1 score: 0.9090909090909091\n",
      "balanced_accuracy : 0.9154656319290466\n",
      "########################################\n",
      "{'C': 1.3563266165995378, 'penalty': 'l2', 'solver': 'saga'}\n",
      "최종 accuracy 평균: 0.865559912095176\n",
      "최종 f1_score 평균: 0.8656513614581667\n",
      "최종 balanced_accuracy 평균: 0.8618654514770276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.865559912095176, 0.8656513614581667, 0.8618654514770276]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticr(parameter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "890d7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter2={'C':1.3563266165995378,'penalty':'elasticnet','solver':'saga','l1_ratio': 0.992994731133511,'max_iter':500}\n",
    "parameter4={'C':1.3563266165995378,'penalty':'elasticnet','solver':'saga','l1_ratio':  0.992994731133511,'max_iter':700}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "64f52ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter3={'C': 2.7349515186346802, 'l1_ratio': 0.1998498315895627,'max_iter':500,'penalty':'elasticnet','solver':'saga'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "000a4cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "train set : ~ 910\n",
      "test set :  1011\n",
      "accuracy score: 0.7901234567901234\n",
      "f1 score: 0.8411214953271028\n",
      "balanced_accuracy : 0.7566287878787878\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1011\n",
      "test set :  1112\n",
      "accuracy score: 0.7738095238095238\n",
      "f1 score: 0.7956989247311829\n",
      "balanced_accuracy : 0.7768009075439593\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1112\n",
      "test set :  1213\n",
      "accuracy score: 0.8705882352941177\n",
      "f1 score: 0.8493150684931505\n",
      "balanced_accuracy : 0.8728571428571428\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1213\n",
      "test set :  1314\n",
      "accuracy score: 0.8764044943820225\n",
      "f1 score: 0.8135593220338982\n",
      "balanced_accuracy : 0.8486842105263157\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1314\n",
      "test set :  1415\n",
      "accuracy score: 0.8765432098765432\n",
      "f1 score: 0.8780487804878049\n",
      "balanced_accuracy : 0.8765243902439024\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1415\n",
      "test set :  1516\n",
      "accuracy score: 0.9186046511627907\n",
      "f1 score: 0.9195402298850575\n",
      "balanced_accuracy : 0.9188311688311688\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1516\n",
      "test set :  1617\n",
      "accuracy score: 0.8481012658227848\n",
      "f1 score: 0.8536585365853658\n",
      "balanced_accuracy : 0.8594771241830066\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1617\n",
      "test set :  1718\n",
      "accuracy score: 0.9146341463414634\n",
      "f1 score: 0.9278350515463918\n",
      "balanced_accuracy : 0.91875\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1718\n",
      "test set :  1819\n",
      "accuracy score: 0.8902439024390244\n",
      "f1 score: 0.891566265060241\n",
      "balanced_accuracy : 0.895933014354067\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1819\n",
      "test set :  1920\n",
      "accuracy score: 0.8795180722891566\n",
      "f1 score: 0.8863636363636365\n",
      "balanced_accuracy : 0.8789198606271778\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1920\n",
      "test set :  2021\n",
      "accuracy score: 0.9058823529411765\n",
      "f1 score: 0.8947368421052632\n",
      "balanced_accuracy : 0.9032705099778271\n",
      "########################################\n",
      "{'C': 1.3563266165995378, 'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.992994731133511, 'max_iter': 500}\n",
      "최종 accuracy 평균: 0.8676775737407934\n",
      "최종 f1_score 평균: 0.8683131047835542\n",
      "최종 balanced_accuracy 평균: 0.8642433742748504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8676775737407934, 0.8683131047835542, 0.8642433742748504]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticr(parameter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "73654df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "train set : ~ 910\n",
      "test set :  1011\n",
      "accuracy score: 0.7901234567901234\n",
      "f1 score: 0.8411214953271028\n",
      "balanced_accuracy : 0.7566287878787878\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1011\n",
      "test set :  1112\n",
      "accuracy score: 0.7738095238095238\n",
      "f1 score: 0.7956989247311829\n",
      "balanced_accuracy : 0.7768009075439593\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1112\n",
      "test set :  1213\n",
      "accuracy score: 0.8705882352941177\n",
      "f1 score: 0.8493150684931505\n",
      "balanced_accuracy : 0.8728571428571428\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1213\n",
      "test set :  1314\n",
      "accuracy score: 0.8764044943820225\n",
      "f1 score: 0.8135593220338982\n",
      "balanced_accuracy : 0.8486842105263157\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1314\n",
      "test set :  1415\n",
      "accuracy score: 0.8765432098765432\n",
      "f1 score: 0.8780487804878049\n",
      "balanced_accuracy : 0.8765243902439024\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1415\n",
      "test set :  1516\n",
      "accuracy score: 0.9186046511627907\n",
      "f1 score: 0.9195402298850575\n",
      "balanced_accuracy : 0.9188311688311688\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1516\n",
      "test set :  1617\n",
      "accuracy score: 0.8481012658227848\n",
      "f1 score: 0.8536585365853658\n",
      "balanced_accuracy : 0.8594771241830066\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1617\n",
      "test set :  1718\n",
      "accuracy score: 0.9146341463414634\n",
      "f1 score: 0.9278350515463918\n",
      "balanced_accuracy : 0.91875\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1718\n",
      "test set :  1819\n",
      "accuracy score: 0.8902439024390244\n",
      "f1 score: 0.891566265060241\n",
      "balanced_accuracy : 0.895933014354067\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1819\n",
      "test set :  1920\n",
      "accuracy score: 0.8795180722891566\n",
      "f1 score: 0.8863636363636365\n",
      "balanced_accuracy : 0.8789198606271778\n",
      "########################################\n",
      "########################################\n",
      "train set : ~ 1920\n",
      "test set :  2021\n",
      "accuracy score: 0.9058823529411765\n",
      "f1 score: 0.8947368421052632\n",
      "balanced_accuracy : 0.9032705099778271\n",
      "########################################\n",
      "{'C': 1.3563266165995378, 'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.992994731133511, 'max_iter': 700}\n",
      "최종 accuracy 평균: 0.8676775737407934\n",
      "최종 f1_score 평균: 0.8683131047835542\n",
      "최종 balanced_accuracy 평균: 0.8642433742748504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8676775737407934, 0.8683131047835542, 0.8642433742748504]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticr(parameter4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f3750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
