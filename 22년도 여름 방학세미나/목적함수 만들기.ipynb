{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4017b295",
   "metadata": {},
   "source": [
    "## XGB, LightGBM ,RandomForestClassifier objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61da8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import optuna\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import psutil\n",
    "import time \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58cee29",
   "metadata": {},
   "source": [
    "1.XGBoost 최적 하이퍼 파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d944f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"eval_metric\":'mlogloss',\n",
    "        \"booster\": 'gbtree',\n",
    "        'tree_method':'gpu_hist', 'predictor':'gpu_predictor', 'gpu_id': 0, # GPU 사용시 \n",
    "        \"verbosity\": 0,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_uniform('learning_rate', 0.0001, 0.99),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\", 1000, 10000, step=100),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.5, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-2, 1),\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-2, 1),\n",
    "        'subsample': trial.suggest_discrete_uniform('subsample', 0.6, 1.0, 0.05),     \n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 15),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.1, 1.0, log=True),\n",
    "    }\n",
    "    \n",
    "    str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 50)\n",
    "    \n",
    "    f1score=[]\n",
    "    \n",
    "    for train_index, test_index in str_kf.split(x, y):\n",
    "        x_train, x_val = x[train_index], x[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "        \n",
    "        model = xgb.XGBClassifier(**params, random_state = 1234, use_label_encoder = False)\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        y_pred=model.predict(x_val)\n",
    "        f1score.append(f1_score(y_val,y_pred))\n",
    "        total=np.mean(f1score)\n",
    "        \n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d44e09f",
   "metadata": {},
   "source": [
    "2. SVC (linear Kernal) 하이퍼 파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d436a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d5267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_svc(trial):\n",
    "    svc_c = trial.suggest_float(\"C\", 1e-10, 1e10, log=True)\n",
    "    model = sklearn.svm.SVC(C=svc_c, gamma=\"auto\")\n",
    "    \n",
    "    str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 50)\n",
    "    f1score=[]\n",
    "    \n",
    "    for train_index, test_index in str_kf.split(x, y):\n",
    "        x_train, x_val = x[train_index], x[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        y_pred=model.predict(x_val)\n",
    "        f1score.append(f1_score(y_val,y_pred))\n",
    "        total=np.mean(f1score)\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63b659",
   "metadata": {},
   "source": [
    "3. LightGBM 파이퍼 파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f0ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5533a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "    \n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 1024, step=1, log=True), \n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10, step=1, log=False), \n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.1, log=True), \n",
    "        'n_estimators': trial.suggest_int('n_estimators', 8, 1024, step=1, log=True), \n",
    "        'objective': 'multiclass', \n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50, step=1, log=False), \n",
    "        'subsample': trial.suggest_uniform('subsample', 0.7, 1.0), \n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 10.0),\n",
    "        'random_state': 0\n",
    "    }\n",
    "    \n",
    "    \n",
    "    str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 50)\n",
    "    f1score=[]\n",
    "    \n",
    "    for train_index, test_index in str_kf.split(x, y):\n",
    "        x_train, x_val = x[train_index], x[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "        \n",
    "        model=lgb_clf= lgb.LGBMClassifier(**params)\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        y_pred=model.predict(x_val)\n",
    "        f1score.append(f1_score(y_val,y_pred))\n",
    "        total=np.mean(f1score)\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087076e9",
   "metadata": {},
   "source": [
    "4. RandomForestClassifier 하이퍼 파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9105446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rfc(trial):\n",
    "    \n",
    "    params={\n",
    "        \n",
    "        'max_depth' : trial.suggest_int('max_depth', 1, 10),\n",
    "        'max_leaf_nodes' : trial.suggest_int('max_leaf_nodes', 2, 1000),\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 100, 500) \n",
    "    \n",
    "    }\n",
    "    \n",
    "    str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 50)\n",
    "    f1score=[]\n",
    "    \n",
    "    for train_index, test_index in str_kf.split(x, y):\n",
    "        x_train, x_val = x[train_index], x[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "        \n",
    "        model=RandomForestClassifier(**params)\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        y_pred=model.predict(x_val)\n",
    "        f1score.append(f1_score(y_val,y_pred))\n",
    "        total=np.mean(f1score)\n",
    "    \n",
    "    return total\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939b58d",
   "metadata": {},
   "source": [
    "5. isolation forest 하이퍼 파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d5af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_if(trial):\n",
    "    \n",
    "    params={\n",
    "        \n",
    "        'n_estimators' :trial.suggest_int('n_estimators', 1, 200),\n",
    "        'max_samples' : trial.suggest_uniform('max_samples', 0.0, 1.0),\n",
    "        'contamination' : trial.suggest_loguniform('contamination', 1e-6, 1e-1),\n",
    "        'max_features' : trial.suggest_uniform('max_features', 0.0, 1.0),\n",
    "        'bootstrap' : trial.suggest_categorical('bootstrap', [True, False]) }\n",
    "    \n",
    "    # 아래 잘못된 변수명 있으면 고치기 \n",
    "    \n",
    "    clf = IsolationForest(**params)\n",
    "    clf.fit(X_train) \n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    y_pred_test = pd.DataFrame(y_pred_test)\n",
    "    y_pred = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(y_pred_test)):\n",
    "        if y_pred_test.iloc[i,0] == 1 :\n",
    "            y_pred_test.iloc[i,0] = 0\n",
    "        else:\n",
    "            y_pred_test.iloc[i,0] = 1\n",
    "        \n",
    "    f1 = f1_score(y_test, y_pred_test,average='micro')\n",
    "    \n",
    "    return f1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
